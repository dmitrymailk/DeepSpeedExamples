{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /cephfs/home/konovalov/ru_self_instruct/databricks-dolly-15k_translated_fixed.json\n",
    "# /cephfs/home/konovalov/ru_self_instruct/self_instruct_translated.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using custom data configuration default-ce37cf520ab74917\n",
      "Found cached dataset json (/home/kosenko/.cache/huggingface/datasets/json/default-ce37cf520ab74917/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['completion', 'completion_translated', 'prompt', 'prompt_translated'],\n",
       "        num_rows: 82600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "translated_path = (\n",
    "    \"/cephfs/home/konovalov/ru_self_instruct/self_instruct_translated.json\"\n",
    ")\n",
    "\n",
    "data = load_dataset(\"json\", data_files=translated_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening the indices: 100%|██████████| 81/81 [00:04<00:00, 18.00ba/s]\n",
      "Flattening the indices: 100%|██████████| 2/2 [00:00<00:00, 28.34ba/s]                           \n",
      "                                                                                              \r"
     ]
    }
   ],
   "source": [
    "save_dataset = \"/home/kosenko/deepspeed/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/datasets/self_instruct_translated/\"\n",
    "data['train'].train_test_split(train_size=0.98, test_size=0.02).save_to_disk(save_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completion': \" 1. Make a schedule for studying and stick to it.\\n2. Study in the same place every time.\\n3. Set goals for yourself.\\n4. Take breaks when you need them.\\n5. Don't cram before an exam.\\n6. Get enough sleep.\\n7. Eat healthy food.\\n8. Exercise regularly.\\n9. Find a study partner.\\n10. Reward yourself after completing a task.\",\n",
       " 'completion_translated': '1. Составьте график учебы и придерживайтесь его. Учитесь в одном и том же месте каждые часы.Ставьте перед собой цели. Сделайте перерывы, когда они вам нужны. Не суетитесь перед экзаменом. Достаточно спите. Ешьте здоровую пищу. Регулярно занимайтесь физическими упражнениями. Найдите занятие. Вознаграждайте себя после выполнения задания.',\n",
       " 'prompt': 'Make a list of 10 ways to help students improve their study skills.\\n\\nOutput:',\n",
       " 'prompt_translated': 'Составьте список из 10 способов помочь студентам улучшить свои навыки учебы.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1e38304b6910746b\n",
      "Found cached dataset json (/home/kosenko/.cache/huggingface/datasets/json/default-1e38304b6910746b/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n",
      "100%|██████████| 1/1 [00:00<00:00, 702.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['category', 'context', 'context_translated', 'instruction', 'instruction_translated', 'response', 'response_translated'],\n",
       "        num_rows: 15000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_path = (\n",
    "    \"/cephfs/home/konovalov/ru_self_instruct/databricks-dolly-15k_translated_fixed.json\"\n",
    ")\n",
    "\n",
    "data = load_dataset(\"json\", data_files=translated_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening the indices: 100%|██████████| 15/15 [00:01<00:00, 11.37ba/s]\n",
      "Flattening the indices: 100%|██████████| 1/1 [00:00<00:00, 55.65ba/s]                           \n",
      "                                                                                            \r"
     ]
    }
   ],
   "source": [
    "save_dataset = \"/home/kosenko/deepspeed/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/datasets/databricks_dolly_15k_translated_fixed/\"\n",
    "data['train'].train_test_split(train_size=0.98, test_size=0.02).save_to_disk(save_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'closed_qa',\n",
       " 'context': \"Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.[3] It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.[4]\",\n",
       " 'context_translated': 'Авиакомпания Virgin Australia, торговое название Virgin Australia Airlines Pty Ltd, базируется в Австралии. Это крупнейшая авиакомпания по размеру флота, использующая бренд Virgin. Она начала обслуживать 31 августа 2000 года как Virgin Blue, с двумя самолетами на одном маршруте. [3] Она внезапно оказалась крупной авиакомпанией на внутреннем рынке Австралии после краха Ansett Australia в сентябре 2001 года. С тех пор авиакомпания выросла до прямого обслуживания 32 городов Австралии, начиная с Брисбена, Мельбурна и Сиднея. [4]',\n",
       " 'instruction': 'When did Virgin Australia start operating?',\n",
       " 'instruction_translated': 'Когда Virgin Australia начала работать?',\n",
       " 'response': 'Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.',\n",
       " 'response_translated': '31 августа 2000 года авиакомпания Virgin Australia начала полеты под названием Virgin Blue с двумя самолетами на одном маршруте.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptRawDataset(object):\n",
    "    def __init__(self, output_path, seed, local_rank):\n",
    "        self.output_path = output_path\n",
    "        self.seed = seed\n",
    "        self.local_rank = local_rank\n",
    "\n",
    "    def get_train_data(self):\n",
    "        return\n",
    "\n",
    "    def get_eval_data(self):\n",
    "        return\n",
    "\n",
    "    # The prompt should be in the format of: \" Human: \" + actual_prompt_sentence + \" Assistant:\"\n",
    "    def get_prompt(self, sample):\n",
    "        return\n",
    "\n",
    "    # The chosen response should be in the format of: \" \" + actual_response_sentence\n",
    "    def get_chosen(self, sample):\n",
    "        return\n",
    "\n",
    "    # The rejected response should be in the format of: \" \" + actual_response_sentence\n",
    "    # If the dataset does not have rejected response, return None\n",
    "    def get_rejected(self, sample):\n",
    "        return\n",
    "\n",
    "    def get_prompt_and_chosen(self, sample):\n",
    "        return\n",
    "\n",
    "    def get_prompt_and_rejected(self, sample):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuInstructTranslated(PromptRawDataset):\n",
    "    def __init__(self, output_path, seed, local_rank):\n",
    "        super().__init__(output_path, seed, local_rank)\n",
    "        self.dataset_name = \"self_instruct_translated\"\n",
    "        self.dataset_name_clean = \"self_instruct_translated\"\n",
    "        self.raw_datasets = load_dataset(\"/home/kosenko/deepspeed/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/datasets/self_instruct_translated/\")\n",
    "\n",
    "    def get_train_data(self):\n",
    "        return self.raw_datasets['train']\n",
    "\n",
    "    def get_eval_data(self):\n",
    "        return self.raw_datasets['test']\n",
    "\n",
    "    # The prompt should be in the format of: \" Human: \" + actual_prompt_sentence + \" Assistant:\"\n",
    "    def get_prompt(self, sample):\n",
    "        return f\"Human: {sample['prompt_translated']} Assistant:\"\n",
    "\n",
    "    # The chosen response should be in the format of: \" \" + actual_response_sentence\n",
    "    def get_chosen(self, sample):\n",
    "        return f\" {sample['completion_translated']}\"\n",
    "\n",
    "    # The rejected response should be in the format of: \" \" + actual_response_sentence\n",
    "    # If the dataset does not have rejected response, return None\n",
    "    def get_rejected(self, sample):\n",
    "        return\n",
    "\n",
    "    def get_prompt_and_chosen(self, sample):\n",
    "        return self.get_prompt(sample) + self.get_chosen(sample)\n",
    "\n",
    "    def get_prompt_and_rejected(self, sample):\n",
    "        return\n",
    "    \n",
    "    \n",
    "class RuDollyInstructTranslated(PromptRawDataset):\n",
    "    def __init__(self, output_path, seed, local_rank):\n",
    "        super().__init__(output_path, seed, local_rank)\n",
    "        self.dataset_name = \"databricks_dolly_15k_translated_fixed\"\n",
    "        self.dataset_name_clean = \"databricks_dolly_15k_translated_fixed\"\n",
    "        self.raw_datasets = load_dataset(\"/home/kosenko/deepspeed/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/datasets/databricks_dolly_15k_translated_fixed/\")\n",
    "\n",
    "    def get_train_data(self):\n",
    "        return self.raw_datasets['train']\n",
    "\n",
    "    def get_eval_data(self):\n",
    "        return self.raw_datasets['test']\n",
    "\n",
    "    # The prompt should be in the format of: \" Human: \" + actual_prompt_sentence + \" Assistant:\"\n",
    "    def get_prompt(self, sample):\n",
    "        return f\"Human: {sample['context_translated']} {sample['instruction_translated']} Assistant:\"\n",
    "\n",
    "    # The chosen response should be in the format of: \" \" + actual_response_sentence\n",
    "    def get_chosen(self, sample):\n",
    "        return f\" {sample['response_translated']}\"\n",
    "\n",
    "    # The rejected response should be in the format of: \" \" + actual_response_sentence\n",
    "    # If the dataset does not have rejected response, return None\n",
    "    def get_rejected(self, sample):\n",
    "        return\n",
    "\n",
    "    def get_prompt_and_chosen(self, sample):\n",
    "        return self.get_prompt(sample) + self.get_chosen(sample)\n",
    "\n",
    "    def get_prompt_and_rejected(self, sample):\n",
    "        return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
