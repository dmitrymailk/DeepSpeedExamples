{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/HuggingFaceH4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/yaodongC/awesome-instruction-dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch\n",
    "from easynmt import EasyNMT\n",
    "from optimum.bettertransformer import BetterTransformer\n",
    "from datasets import load_from_disk, load_dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "class Translator:\n",
    "    def __init__(self, \n",
    "        model_name: str,\n",
    "        device = 'cuda'\n",
    "    ):\n",
    "        self.model_name = model_name\n",
    "        self.device = device\n",
    "        self.model = None\n",
    "        self.tokenizer = None\n",
    "        self.init()\n",
    "    \n",
    "    def init(self):\n",
    "        print(\"Init model.\")\n",
    "        if self.model_name == \"facebook/nllb-200-3.3B\":\n",
    "            self.model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "                self.model_name, \n",
    "                use_auth_token=True,\n",
    "            )\n",
    "            self.model = BetterTransformer.transform(self.model)\n",
    "            self.model.eval()\n",
    "            self.model = torch.compile(self.model)\n",
    "            self.model = self.model.to(self.device)\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "                self.model_name,\n",
    "                use_auth_token=True,\n",
    "            )\n",
    "        elif self.model_name == \"facebook/wmt21-dense-24-wide-en-x\":\n",
    "            self.model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "                self.model_name, \n",
    "                use_auth_token=True,\n",
    "            )\n",
    "            self.model = BetterTransformer.transform(self.model)\n",
    "            self.model.eval()\n",
    "            self.model = torch.compile(self.model)\n",
    "            self.model = self.model.to(self.device)\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "                self.model_name,\n",
    "                use_auth_token=True,\n",
    "            )\n",
    "        elif self.model_name == \"opus-mt\":\n",
    "            self.model = EasyNMT(self.model_name)\n",
    "            \n",
    "        print(\"Model is initialized.\")\n",
    "    \n",
    "    def translate(self, text: str):\n",
    "        func_map = {\n",
    "            \"facebook/nllb-200-3.3B\": self.nllb_translate,\n",
    "            \"opus-mt\": self.opusmt_translate,\n",
    "            \"facebook/wmt21-dense-24-wide-en-x\": self.wmt21_translate\n",
    "        }\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            return func_map[self.model_name](text)\n",
    "    \n",
    "    def __call__(self, text: str):\n",
    "        return self.translate(text=text)\n",
    "    \n",
    "    def nllb_translate(self, text: str):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\")\n",
    "        inputs = self.to_device(inputs=inputs)\n",
    "        translated_tokens = self.model.generate(\n",
    "            **inputs, \n",
    "            forced_bos_token_id=self.tokenizer.lang_code_to_id[\"rus_Cyrl\"],\n",
    "        )\n",
    "        return self.tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
    "    \n",
    "    def opusmt_translate(self, text: str):\n",
    "        return self.model.translate(\n",
    "            text,\n",
    "            source_lang=\"en\" ,\n",
    "            target_lang='ru'\n",
    "        )\n",
    "\n",
    "    def wmt21_translate(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\")\n",
    "        inputs = self.to_device(inputs=inputs)\n",
    "        translated_tokens = self.model.generate(\n",
    "            **inputs, \n",
    "            forced_bos_token_id=self.tokenizer.get_lang_id(\"ru\"),\n",
    "        )\n",
    "        return self.tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
    "    \n",
    "    def to_device(self, inputs):\n",
    "        for key in inputs.keys():\n",
    "            inputs[key] = inputs[key].to(self.device)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EasyNMT(\"facebook/wmt21-dense-24-wide-en-x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init model.\n",
      "Model is initialized.\n"
     ]
    }
   ],
   "source": [
    "# 2 min 40 sec - 50\n",
    "# model_name = \"facebook/nllb-200-3.3B\"\n",
    "# 6 min 5 sec - 50\n",
    "# model_name = \"facebook/wmt21-dense-24-wide-en-x\"\n",
    "# 45 sec - 50\n",
    "model_name = \"opus-mt\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "translator = Translator(model_name=model_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1336: UserWarning: Using `max_length`'s default (512) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Приветствую мир'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(\"hello world\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### databricks/databricks-dolly-15k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset json (/home/kosenko/.cache/huggingface/datasets/databricks___json/databricks--databricks-dolly-15k-aae1918f8081f1c6/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n",
      "100%|██████████| 1/1 [00:00<00:00, 642.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'context', 'response', 'category'],\n",
       "        num_rows: 15014\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset(\"databricks/databricks-dolly-15k\")\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'When did Virgin Australia start operating?',\n",
       " 'context': \"Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.[3] It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.[4]\",\n",
       " 'response': 'Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.',\n",
       " 'category': 'closed_qa'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"/home/kosenko/deepspeed/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/datasets/translations_examples/\"\n",
    "model_path = model_name.replace(\"/\", \"_\")\n",
    "save_path = f\"{base_folder}{model_path}.csv\"\n",
    "\n",
    "assert not os.path.isfile(save_path), f'File {model_path} exists'\n",
    "\n",
    "fields = [\"context\", \"instruction\", \"response\"]\n",
    "\n",
    "dataset_map = {item: [] for item in fields}\n",
    "for item in fields:\n",
    "    dataset_map[f'{item}_translated'] = []\n",
    "\n",
    "for i, example in enumerate(data[\"train\"]):\n",
    "    print(\"Progress \",i)\n",
    "    for field in fields:\n",
    "        print(f\"Field name: {field}\")\n",
    "        print(\"Original: \", example[field])\n",
    "        text = example[field]\n",
    "        translated = translator(text=text)\n",
    "        print(\"Translated: \", translated)\n",
    "        dataset_map[field].append(example[field])\n",
    "        dataset_map[f'{field}_translated'].append(translated)\n",
    "        print()\n",
    "    print(\"==\" * 100)\n",
    "\n",
    "    if i > 50:\n",
    "        break\n",
    "pd.DataFrame(data=dataset_map).to_csv(save_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
